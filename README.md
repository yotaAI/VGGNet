
# VGGNet 

ğŸ› VGG stands for Visual Geometry Group and consists of blocks, where each block is composed of 2D Convolution and Max Pooling layers.

ğŸ› I [@yota](https://github.com/yotaAI) am Implementing the model from Paper ğŸ“„ : https://arxiv.org/abs/1409.1556



## ğŸ“ Knowledge

The model owner created 3 different models for VGGNet
`ğŸ“VGG11 : 11 Weights`
`ğŸ“VGG13 : 13 Weights`
`ğŸ“VGG16 : 16 Weights`
`ğŸ“VGG19 : 19 Weights`

âœï¸ Currently I am implementing the training setup of VGG11 model with randomly initialized weights.

âœï¸ As mentioned in the paper the larger of models `VGG13 VGG16 VGG19` are initialized from `Trained VGG11`.
 

## ğŸ—ƒï¸ Dataset

ğŸ—ï¸ For Learning Purpose I am using [Flower Dataset](https://www.kaggle.com/datasets/alxmamaev/flowers-recognition#).

ğŸ—ï¸ Keep the Flower Datset inside `./dataset`.

ğŸ—ï¸ Dataset is having : 
        
        ğŸŒ¼ daisy
        ğŸŒ¼ rose
        ğŸŒ¼ tulip
        ğŸŒ¼ dandelion
        ğŸŒ¼ sunflower


## ğŸ¤– Training

ğŸ·ï¸ Before Starting Training  Check the `HyperParameter` section of `train.py`.
ğŸ·ï¸ Now run the `train.py` and Boom!ğŸ¤¯
ğŸ·ï¸ Training Loss will be calculated in `loss.txt`
```bash
python3 train.py
```

## ğŸ¥·ğŸ» Ninja Tech

âš¡ï¸ Machine Learning âš¡ï¸ Deep LearningÂ âš¡ï¸ CNN âš¡ï¸


