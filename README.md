
# VGGNet 

ğŸ› VGG stands for Visual Geometry Group and consists of blocks, where each block is composed of 2D Convolution and Max Pooling layers.

ğŸ› I [@yota](https://github.com/yotaAI) am Implementing the model from Paper ğŸ“„ : https://arxiv.org/abs/1409.1556



## ğŸ“ Knowledge

The model owner created 3 different models for VGGNet
`ğŸ“VGG11 : 11 Weights`
`ğŸ“VGG13 : 13 Weights`
`ğŸ“VGG16 : 16 Weights`
`ğŸ“VGG19 : 19 Weights`

âœï¸ Previously I was implementing the training setup of VGG11 model with randomly initialized weights Currently I am initializaing model's weight with Normal Distribution with `0` mean and `10^-2` variance and bias with `0`.

âœï¸ As mentioned in the paper the larger of models `VGG13 VGG16 VGG19` are initialized from `Trained VGG11`.

âœï¸ Or we can train them directly with normal distribution of weights.
 

## ğŸ—ƒï¸ Dataset

ğŸ—ï¸ For Learning Purpose I am using [Flower Dataset](https://www.kaggle.com/datasets/alxmamaev/flowers-recognition#).

ğŸ—ï¸ Keep the Flower Datset inside `./dataset`.

ğŸ—ï¸ Dataset is having : 
        
        ğŸŒ¼ daisy
        ğŸŒ¼ rose
        ğŸŒ¼ tulip
        ğŸŒ¼ dandelion
        ğŸŒ¼ sunflower

ğŸ—ï¸As described in paper[Page 4] The model is first trained on dataset of `Scale=256`  then the pretrained model is again trained on `Scale=384` with `Learning Rate = 10^-3`.


## ğŸ¤– Training VGG

ğŸ·ï¸ Now run the `training.py` and Boom!ğŸ¤¯
```bash
python3 training.py -m VGG11 -mp ./vgg_11/ -l loss_vgg11.txt
```

ğŸ·ï¸ Model will be saved in the path you mentiond in `-mp`.

ğŸ·ï¸ for more details you can check `python3 training.py --help`



## ğŸ¥·ğŸ» Ninja Tech

âš¡ï¸ Machine Learning âš¡ï¸ Deep Learning âš¡ï¸ CNN âš¡ï¸


