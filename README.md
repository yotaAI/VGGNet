
# VGGNet 

ğŸ› VGG stands for Visual Geometry Group and consists of blocks, where each block is composed of 2D Convolution and Max Pooling layers.

ğŸ› I [@yota](https://github.com/yotaAI) am Implementing the model from Paper ğŸ“„ : https://arxiv.org/abs/1409.1556



## ğŸ“ Knowledge

The model owner created 3 different models for VGGNet
`ğŸ“VGG11 : 11 Weights`
`ğŸ“VGG13 : 13 Weights`
`ğŸ“VGG16 : 16 Weights`
`ğŸ“VGG19 : 19 Weights`

âœï¸ Currently I am implementing the training setup of VGG11 model with randomly initialized weights.

âœï¸ As mentioned in the paper the larger of models `VGG13 VGG16 VGG19` are initialized from `Trained VGG11`.
 

## ğŸ—ƒï¸ Dataset

ğŸ—ï¸ For Learning Purpose I am using [Flower Dataset](https://www.kaggle.com/datasets/alxmamaev/flowers-recognition#).

ğŸ—ï¸ Keep the Flower Datset inside `./dataset`.

ğŸ—ï¸ Dataset is having : 
        
        ğŸŒ¼ daisy
        ğŸŒ¼ rose
        ğŸŒ¼ tulip
        ğŸŒ¼ dandelion
        ğŸŒ¼ sunflower


## ğŸ¤– Training VGG11

ğŸ·ï¸ Before Starting Training  Check the `HyperParameter` section of `train_vgg11.py`.

ğŸ·ï¸ Now run the `train_vgg11.py` and Boom!ğŸ¤¯

ğŸ·ï¸ Training Loss will be calculated in `loss_vgg11.txt`

ğŸ·ï¸ Model will be saved in the path mentioned in the `HyperParamet` section of the script.

ğŸ·ï¸ The `first conv layer` and `last fully connected layers` of `VGG16` will be taken from trained `VGG11` model. 

```bash
python3 train_vgg11.py
```

## ğŸ¤– Training VGG16

ğŸ·ï¸ Before Starting Training  Check the `HyperParameter` section of `train_vgg16.py`.

ğŸ·ï¸ If you are frashly training the model, you have to first Pretrained `VGG11`.

ğŸ·ï¸ Provide the path of the trained `VGG11` model in `vgg_11_path` of `train_vgg16.py`

ğŸ·ï¸ Now run the `train_vgg16.py` and Boom!ğŸ¤¯

ğŸ·ï¸ Training Loss will be calculated in `loss_vgg16.txt`

```bash
python3 train_vgg16.py
```

## ğŸ¥·ğŸ» Ninja Tech

âš¡ï¸ Machine Learning âš¡ï¸ Deep LearningÂ âš¡ï¸ CNN âš¡ï¸


